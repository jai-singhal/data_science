{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-09T18:02:24.386115Z",
     "start_time": "2019-03-09T18:02:24.277588Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "import pickle\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import random\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from nltk.classify import ClassifierI\n",
    "from statistics import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-09T15:53:16.552794Z",
     "start_time": "2019-03-09T15:53:16.546775Z"
    }
   },
   "outputs": [],
   "source": [
    "train_file = open(\"./train.ft.txt\", \"r\", encoding=\"utf-8\")\n",
    "test_file = open(\"./test.ft.txt\", \"r\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-09T17:43:06.419671Z",
     "start_time": "2019-03-09T17:41:45.618558Z"
    }
   },
   "outputs": [],
   "source": [
    "training_set = [train_file.readline() for _ in range(8000)]\n",
    "stop_words = stopwords.words(\"english\")\n",
    "\n",
    "#  j is adjective, r is adverb, and v is verb\n",
    "#allowed_word_types = [\"J\",\"R\",\"V\"]\n",
    "allowed_word_types = [\"J\"]\n",
    "documents = []\n",
    "all_words = []\n",
    "\n",
    "for i,line in enumerate(training_set):\n",
    "    doc = re.split(r\"__label__(\\d+) \", str(line))[1:]\n",
    "    sentiment = \"nag\" if doc[0] == \"1\" else \"pos\"\n",
    "    review = doc[1]\n",
    "    documents.append([review, sentiment])\n",
    "    words = [w for w in word_tokenize(review) if w not in stop_words]\n",
    "    pos = nltk.pos_tag(words)\n",
    "    for w in pos:\n",
    "        if w[1][0] in allowed_word_types:\n",
    "            all_words.append(w[0].lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-09T17:47:35.336351Z",
     "start_time": "2019-03-09T17:45:09.468206Z"
    }
   },
   "outputs": [],
   "source": [
    "all_words = nltk.FreqDist(all_words)\n",
    "\n",
    "word_features = list(all_words.keys())[:5000] # top occuring words\n",
    "\n",
    "def find_features(document):\n",
    "    words = word_tokenize(document)\n",
    "    features = {}\n",
    "    for w in word_features:\n",
    "        features[w] = (w in words)\n",
    "\n",
    "    return features\n",
    "\n",
    "# creates a list of dictionary of all_words with keys and value as \n",
    "# (if particular adjective found in that particluar document)\n",
    "featuresets = [(find_features(rev), category) for (rev, category) in documents]\n",
    "\n",
    "random.shuffle(featuresets)\n",
    "testing_set = featuresets[1600:]\n",
    "training_set = featuresets[:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-09T18:07:21.148434Z",
     "start_time": "2019-03-09T18:03:40.265102Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Naive Bayes Algo accuracy percent: 70.75\n",
      "Most Informative Features\n",
      "               wonderful = True              pos : nag    =      9.6 : 1.0\n",
      "                    easy = True              pos : nag    =      8.8 : 1.0\n",
      "                    poor = True              nag : pos    =      7.9 : 1.0\n",
      "                   video = True              pos : nag    =      7.4 : 1.0\n",
      "                   worst = True              nag : pos    =      6.6 : 1.0\n",
      "            disappointed = True              nag : pos    =      5.8 : 1.0\n",
      "                   wrong = True              nag : pos    =      5.3 : 1.0\n",
      "                 plastic = True              nag : pos    =      5.3 : 1.0\n",
      "                      us = True              pos : nag    =      5.3 : 1.0\n",
      "               excellent = True              pos : nag    =      5.3 : 1.0\n",
      "                  listen = True              pos : nag    =      5.3 : 1.0\n",
      "                  return = True              nag : pos    =      4.7 : 1.0\n",
      "                    best = True              pos : nag    =      4.7 : 1.0\n",
      "                  photos = True              pos : nag    =      4.6 : 1.0\n",
      "                  needed = True              pos : nag    =      4.6 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
    "print(\"Original Naive Bayes Algo accuracy percent:\", (nltk.classify.accuracy(classifier, testing_set))*100)\n",
    "classifier.show_most_informative_features(15)\n",
    "\n",
    "save_classifier = open(\"pickled_algos/originalnaivebayes5k.pickle\",\"wb\")\n",
    "pickle.dump(classifier, save_classifier)\n",
    "save_classifier.close()\n",
    "\n",
    "MNB_classifier = SklearnClassifier(MultinomialNB())\n",
    "MNB_classifier.train(training_set)\n",
    "print(\"MNB_classifier accuracy percent:\", (nltk.classify.accuracy(MNB_classifier, testing_set))*100)\n",
    "\n",
    "save_classifier = open(\"pickled_algos/MNB_classifier5k.pickle\",\"wb\")\n",
    "pickle.dump(MNB_classifier, save_classifier)\n",
    "save_classifier.close()\n",
    "\n",
    "BernoulliNB_classifier = SklearnClassifier(BernoulliNB())\n",
    "BernoulliNB_classifier.train(training_set)\n",
    "print(\"BernoulliNB_classifier accuracy percent:\", (nltk.classify.accuracy(BernoulliNB_classifier, testing_set))*100)\n",
    "\n",
    "save_classifier = open(\"pickled_algos/BernoulliNB_classifier5k.pickle\",\"wb\")\n",
    "pickle.dump(BernoulliNB_classifier, save_classifier)\n",
    "save_classifier.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-09T18:42:48.867170Z",
     "start_time": "2019-03-09T18:41:18.782961Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total failed:  290\n",
      "Total passed:  710\n",
      "accuracy =  71.0\n"
     ]
    }
   ],
   "source": [
    "class VoteClassifier(ClassifierI):\n",
    "    def __init__(self, *classifiers):\n",
    "        self._classifiers = classifiers\n",
    "\n",
    "    def classify(self, features):\n",
    "        votes = []\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "        return mode(votes)\n",
    "\n",
    "    def confidence(self, features):\n",
    "        votes = []\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "\n",
    "        choice_votes = votes.count(mode(votes))\n",
    "        conf = choice_votes / len(votes)\n",
    "        return conf\n",
    "    \n",
    "def find_features(document):\n",
    "    words = word_tokenize(document)\n",
    "    features = {}\n",
    "    for w in word_features:\n",
    "        features[w] = (w in words)\n",
    "    return features\n",
    "\n",
    "\n",
    "def find_sentiment(document):\n",
    "    voted_classifier = VoteClassifier(classifier,\n",
    "                                      MNB_classifier,\n",
    "                                      BernoulliNB_classifier)\n",
    "    features = find_features(document)\n",
    "    return (\n",
    "        voted_classifier.classify(features),\n",
    "        voted_classifier.confidence(features)\n",
    "    )\n",
    "\n",
    "\n",
    "failed = 0\n",
    "totalReviews = 1000\n",
    "\n",
    "test_set = [test_file.readline() for _ in range(totalReviews)]\n",
    "for i,line in enumerate(test_set):\n",
    "    doc = re.split(r\"__label__(\\d+) \", str(line))[1:]\n",
    "    review_sent_actual = \"nag\" if doc[0] == \"1\" else \"pos\"\n",
    "    review = doc[1]\n",
    "    if not review_sent_actual == find_sentiment(review)[0]:\n",
    "        failed += 1\n",
    "print(\"Total failed: \", failed)\n",
    "print(\"Total passed: \", totalReviews-failed)\n",
    "print(\"accuracy = \", (1-failed/totalReviews)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-10T12:34:05.944031Z",
     "start_time": "2019-03-10T12:34:02.789038Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "35 4\n",
      "34\n"
     ]
    }
   ],
   "source": [
    "t = int(input())\n",
    "while(t):\n",
    "    t = t-1\n",
    "    n = int(input())\n",
    "    if(n == 1):\n",
    "        s = input()\n",
    "        print(\"0\")\n",
    "        continue\n",
    "\n",
    "    vector<int> arr(n, 1);\n",
    "    mp_list = [1, 2, 3, 5, 6, 7, 10, 11, 14\n",
    "         15, 21, 22, 30, 33, 35, 42, 55, 66, 70,\n",
    "         77, 105, 110, 154, 165, 210, 231, 330, \n",
    "         385, 462, 770, 1155, 2310]\n",
    "    mp = {}\n",
    "    for i in mp_list:\n",
    "        mp[i] = 0\n",
    "\n",
    "    for(int k = 0; k < n; k++){\n",
    "        string str;\n",
    "        cin >> str;\n",
    "\n",
    "        bool a,e,i,o,u;\n",
    "        a = e = i = o = u = false;\n",
    "\n",
    "        for(int j = 0; j < str.length(); j++){\n",
    "            if(a and e and i and o and u)\n",
    "                break;\n",
    "\n",
    "            if(str[j] == 'a')       a = true;\n",
    "            else if(str[j] == 'e')  e = true;\n",
    "            else if(str[j] == 'i')  i = true;\n",
    "            else if(str[j] == 'o')  o = true;\n",
    "            else if(str[j] == 'u')  u = true;\n",
    "        }\n",
    "\n",
    "        if(a)   arr[k] *= 2;\n",
    "        if(e)   arr[k] *= 3;\n",
    "        if(i)   arr[k] *= 5;\n",
    "        if(o)   arr[k] *= 7;\n",
    "        if(u)   arr[k] *= 11;\n",
    "\n",
    "        for(auto const& x: mp)\n",
    "            if(arr[k] % x.first == 0)\n",
    "                mp[x.first]+=1;\n",
    "\n",
    "        // for(auto const& x: mp)\n",
    "        //     cout << x.first << \" \" << x.second << endl;\n",
    "        // cout << endl;\n",
    "    }\n",
    "\n",
    "    long long count = 0;\n",
    "    for(int k = 0; k < n; k++){\n",
    "        if( mp[ 2310/arr[k] ] > n-1)\n",
    "            count += n-1;\n",
    "        else\n",
    "            count += mp[ 2310/arr[k] ];\n",
    "    }\n",
    "\n",
    "    cout << count/2 << endl;\n",
    "}\n",
    "\n",
    "return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
